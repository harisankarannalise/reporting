# README #

### What is this repository for? ###

* This project allows the user to upload data and retrieve results directly from the Annalise Backend
* TODO: Significantly improve test coverage
* TODO: Add to BuildKite
* TODO: Improve file in/out of main scripts
* TODO: Convert dcm_to_j2k_and_json notebook to a scripts
* TODO: Add instructions for running as docker container

## Pre-requisites ##
```bash
# Install OpenJPEG
# MacOS:
brew install openjpeg
# Ubuntu
sudo apt install libopenjp2-7-dev

# Intall poetry:
# MacOS
brew install poetry
# Ubuntu/Windows
curl -sSL https://raw.githubusercontent.com/python-poetry/poetry/master/get-poetry.py | python -

# For local venv which is helpful for use with vscode:
poetry config virtualenvs.in-project true

# All project dependencies:
poetry install
```

## How to Use ##
## Note for on-prem ##
If running any of the below on-prem, you need to set the self-signed certificate in the command.
e.g. 
```bash 
 REQUESTS_CA_BUNDLE=/path/to/cert/ poetry run python ....
```


### upload_dcms.py ###
Example usage: 
```bash
poetry run python data_uploader/upload_dcms.py -c client_id -s client_secret -a https://api.environment.annaliseai.io -d /path/to/data
```
By default it will group dcm files by StudyInstanceUID but any dicom field can be used for grouping. 
All files in the folder will be uploaded to the Annalise Backend and a csv will be generated containing the 
new IDs



### get_results.py ###
Example usage: 
```bash
poetry run python data_uploader/get_results.py -c client_id -s client_secret -a https://api.environment.annaliseai.io -i output/upload_map_20210704-204221.csv
```
This script will take in a csv (such as the one generated by upload_dcms.py) and download the results for each AccessionNumber uploaded. It will save the results
for each AccessionNumber into a json file with AccessionNumber as the filename.



### dcm_to_j2k_json.py: ###
Example usage: 
```bash
poetry run python scripts/dcm_to_j2k_json.py -d my_dicoms/
```
Creates a j2k and json component of the payload used to push data to the cloud.
(This should be moved out of this repo)



### scripts/loop_uploads.sh ###
Example usage:
```bash
./scripts/loop_uploads.sh -c client_id -s client_secret -a https://api.environment.annaliseai.io -d /path/to/data -n 5
```
This script runs upload_dcms for the specified number of loops, creating new uids and new output files on each run



### Who do I talk to? ###
* Mark Kerollos